{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snowflake imports\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark.functions import udf, col, lit, is_null, iff, initcap\n",
    "\n",
    "# other imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from cryptography.hazmat.primitives.asymmetric import rsa\n",
    "from cryptography.hazmat.primitives.asymmetric import dsa\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "\n",
    "f = open('creds.json')\n",
    "creds = json.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "with open(creds[\"private_key_file\"], \"rb\") as key:\n",
    "    p_key= serialization.load_pem_private_key(\n",
    "        key.read(),\n",
    "        password=creds[\"private_key_passphrase\"].encode(),\n",
    "        backend=default_backend()\n",
    "    )\n",
    "\n",
    "pkb = p_key.private_bytes(\n",
    "    encoding=serialization.Encoding.DER,\n",
    "    format=serialization.PrivateFormat.PKCS8,\n",
    "    encryption_algorithm=serialization.NoEncryption())\n",
    "\n",
    "# import snowflake configurations\n",
    "snowflake_conn_prop = {\n",
    "    \"account\": creds[\"account\"],\n",
    "    \"user\": creds[\"username\"],\n",
    "    \"private_key\":pkb    \n",
    "  }\n",
    "\n",
    "# create the session\n",
    "session = Session.builder.configs(snowflake_conn_prop).create()\n",
    "\n",
    "rolename = creds[\"rolename\"] \n",
    "dbname = creds[\"dbname\"] \n",
    "schemaname = creds[\"schemaname\"] \n",
    "warehouse = creds[\"warehouse\"] \n",
    "\n",
    "session.sql(f\"USE ROLE {rolename}\").collect()\n",
    "session.sql(f\"CREATE DATABASE IF NOT EXISTS {dbname}\").collect()\n",
    "session.sql(f\"CREATE SCHEMA IF NOT EXISTS {dbname}.{schemaname}\").collect()\n",
    "session.sql(f\"CREATE WAREHOUSE  IF NOT EXISTS {warehouse} \\\n",
    "                WAREHOUSE_SIZE = 'SMALL' \\\n",
    "                AUTO_SUSPEND = 300 \\\n",
    "                AUTO_RESUME = TRUE\").collect()\n",
    "session.sql(f\"USE WAREHOUSE {warehouse}\").collect()\n",
    "session.sql(f\"USE SCHEMA {dbname}.{schemaname}\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"raw_telco_data.parquet\"\n",
    "stagename = \"rawdata\"\n",
    "rawtable = \"RAW_PARQUET_DATA\"\n",
    "session.sql (\"CREATE FILE FORMAT IF NOT EXISTS MY_PARQUET_FORMAT TYPE=PARQUET\").collect()\n",
    "# Create Snowflake stage\n",
    "session.sql(f\"create or replace stage {stagename} DIRECTORY = (ENABLE = TRUE);\").collect()\n",
    "\n",
    "datafilepath = creds[\"datafilepath\"]\n",
    "# Put the file in the stage\n",
    "session.file.put(f'{datafilepath}/{filename}',stagename)\n",
    "\n",
    "# Create file format and infer schema to create a table using INFER_SCHEMA builtin function\n",
    "#session.sql(\"CREATE OR REPLACE FILE FORMAT MY_PARQUET_FORMAT TYPE = PARQUET;\")\n",
    "\n",
    "# create the table\n",
    "session.sql(f\"CREATE OR REPLACE \\\n",
    "            TABLE {rawtable} USING TEMPLATE ( \\\n",
    "                SELECT ARRAY_AGG(OBJECT_CONSTRUCT(*)) \\\n",
    "                FROM \\\n",
    "                    TABLE( INFER_SCHEMA( \\\n",
    "                    LOCATION => '@{stagename}/{filename}', \\\n",
    "                    FILE_FORMAT => 'MY_PARQUET_FORMAT' \\\n",
    "                    ) \\\n",
    "                ) \\\n",
    "            );  \").collect()\n",
    "\n",
    "\n",
    "# clear any data in the table just in case\n",
    "dfClear = session.table(rawtable).delete()\n",
    "\n",
    "# read the parquet file \n",
    "dfRaw = session.read.option(\"compression\",\"snappy\").parquet(f\"@{stagename}/{filename}\")\n",
    "dfRaw.copy_into_table(rawtable, FORCE= True)\n",
    "#dfRaw.copy_into_table(rawtable,MATCH_BY_COLUMN_NAME='CASE_SENSITIVE',FORCE= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw=session.table(rawtable).sample(n=50)\n",
    "df_raw.to_pandas() #.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a temporary view on the raw data to use for transformation\n",
    "session.table(\"RAW_PARQUET_DATA\").create_or_replace_temp_view('RAW_STAGE')\n",
    "df_raw_stage = session.table(\"RAW_STAGE\")\n",
    "\n",
    "# loop through columns and rename them\n",
    "for c in df_raw_stage.columns:\n",
    "    df_raw_stage=df_raw_stage.rename(c, c.replace(' ', ''))\n",
    "\n",
    "# write the new table to the warehouse\n",
    "df_raw_stage.write.mode('overwrite').saveAsTable('RAW_STAGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location = df_raw_stage.select(\n",
    "                        col(\"CUSTOMERID\"),\n",
    "                        col(\"STATE\").name(\"STATE\"),\n",
    "                        col(\"CITY\").name(\"CITY\"),\n",
    "                        col(\"ZIPCODE\"),\n",
    "                        col(\"LATLONG\"),\n",
    "                        col(\"LATITUDE\").name(\"LATITUDE\"),\n",
    "                        col(\"LONGITUDE\").name(\"LONGITUDE\"),\n",
    "                        initcap(col(\"COUNTRY\")).alias(\"COUNTRY\")\n",
    "                        )\n",
    "\n",
    "df_location.write.mode('overwrite').saveAsTable('LOCATION')\n",
    "df_location.sample(n=50).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics = df_raw_stage.select(\n",
    "                            col(\"CUSTOMERID\"),\n",
    "                            iff(col(\"GENDER\") == \"M\",lit('Male'),col(\"GENDER\")).name(\"GENDER\"),\n",
    "                            col(\"SENIORCITIZEN\"),\n",
    "                            col(\"PARTNER\"),\n",
    "                            col(\"DEPENDENTS\")\n",
    "                            )\n",
    "\n",
    "df_demographics.write.mode('overwrite').saveAsTable('DEMOGRAPHICS')\n",
    "df_demographics.sample(n=50).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status = df_raw_stage.select(col(\"CUSTOMERID\"),\n",
    "                    col(\"CHURNLABEL\"),\n",
    "                    col(\"CHURNVALUE\"),\n",
    "                    col(\"CHURNSCORE\"),\n",
    "                    iff(is_null(col(\"CHURNREASON\")),lit(\"do not know\"),col(\"CHURNREASON\")).name(\"CHURNREASON\")          \n",
    "                    )\n",
    "\n",
    "df_status.write.mode('overwrite').saveAsTable('STATUS')\n",
    "df_status.sample(n=50).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_services = df_raw_stage.select(col(\"CUSTOMERID\"),\n",
    "                       iff(is_null(col(\"TECHSUPPORT\")),lit('No'),col(\"TECHSUPPORT\")).name(\"TECHSUPPORT\"),\n",
    "                       iff(is_null(col(\"CONTRACT\")),lit(\"Month-to-month\"),col(\"CONTRACT\")).name(\"CONTRACT\"),\n",
    "                       iff(is_null(col(\"PAPERLESSBILLING\")),lit('True'),col(\"PAPERLESSBILLING\")).name(\"PAPERLESSBILLING\"),\n",
    "                       col(\"MONTHLYCHARGES\"),\n",
    "                       col(\"TOTALCHARGES\"),\n",
    "                       col(\"CHURNVALUE\"),\n",
    "                       col(\"TENUREMONTHS\"),\n",
    "                       col(\"PHONESERVICE\"),\n",
    "                       col(\"MULTIPLELINES\"),\n",
    "                       col(\"INTERNETSERVICE\"),\n",
    "                       col(\"ONLINESECURITY\"),\n",
    "                       col(\"ONLINEBACKUP\"),\n",
    "                       col(\"DEVICEPROTECTION\"),\n",
    "                       col(\"STREAMINGTV\"),\n",
    "                       col(\"STREAMINGMOVIES\"),\n",
    "                       col(\"PAYMENTMETHOD\")\n",
    "                      )    \n",
    "\n",
    "df_services.write.mode('overwrite').saveAsTable('SERVICES')\n",
    "df_services.sample(n=50).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDemo = session.table(\"DEMOGRAPHICS\")\n",
    "dfServ = session.table(\"SERVICES\")\n",
    "\n",
    "dfJoin = dfDemo.join(dfServ,dfDemo.col(\"CUSTOMERID\") == dfServ.col(\"CUSTOMERID\")\n",
    "    ).select(dfDemo.CUSTOMERID.alias('CUSTOMERID'), '*')\n",
    "dfJoin.sample(n=50).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern matching and column dropping\n",
    "cols_to_drop=[col for col in dfJoin.columns if \"_CUSTOMERID\" in col]\n",
    "dfJoin=dfJoin.drop(cols_to_drop)\n",
    "\n",
    "# writing to the warehouse\n",
    "dfJoin.write.mode('overwrite').saveAsTable('TELCO_DATASET')\n",
    "dfJoin.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Oct 19 2022, 17:54:22) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe838cc323c855e44cb45e570dd0ea2e8aedb070c6c00f1a77551ac0c2ea2815"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
